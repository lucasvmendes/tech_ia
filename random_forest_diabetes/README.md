# ğŸ©º ClassificaÃ§Ã£o de Diabetes com Random Forest e SMOTE

## ğŸ“˜ DescriÃ§Ã£o do Projeto

Este projeto apresenta a implementaÃ§Ã£o de um **pipeline automatizado em Python** para **classificaÃ§Ã£o de diabetes tipo II**, utilizando o algoritmo **Random Forest** em conjunto com a tÃ©cnica **SMOTE (Synthetic Minority Over-sampling Technique)**.  

O objetivo Ã© investigar a influÃªncia do balanceamento de classes no desempenho de modelos de aprendizado supervisionado, aplicando tÃ©cnicas de prÃ©-processamento, validaÃ§Ã£o cruzada e otimizaÃ§Ã£o estocÃ¡stica de hiperparÃ¢metros.  

---
  
## âš™ï¸ Metodologia

### 1. PrÃ©-processamento
- Tratamento de valores **invÃ¡lidos (0)** em variÃ¡veis fisiologicamente impossÃ­veis: `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`.  
- **ImputaÃ§Ã£o estatÃ­stica** pela mediana (`SimpleImputer`).  
- **NormalizaÃ§Ã£o z-score** com `StandardScaler`.  
- DivisÃ£o **estratificada** em treino e teste (80/20).

### 2. Balanceamento
- AplicaÃ§Ã£o do **SMOTE** (*Chawla et al., 2002*) apenas sobre o conjunto de treino, para gerar amostras sintÃ©ticas da classe minoritÃ¡ria.

### 3. Modelagem e OtimizaÃ§Ã£o
- **Modelo base:** `RandomForestClassifier` (*Breiman, 2001*).  
- **Busca de hiperparÃ¢metros:** `RandomizedSearchCV` com validaÃ§Ã£o cruzada 5-fold e mÃ©trica de otimizaÃ§Ã£o **F1-score**.  

ParÃ¢metros testados:
```python
param_grid = {
    'classifier__n_estimators': [100, 300, 500],
    'classifier__max_depth': [10, 20, None],
    'classifier__min_samples_split': [2, 5],
    'classifier__min_samples_leaf': [1, 2],
    'classifier__max_features': ['sqrt', 'log2']
}
```

### 4. AvaliaÃ§Ã£o
- MÃ©tricas utilizadas: *precision*, *recall*, *F1-score* e *accuracy*.  
- VisualizaÃ§Ãµes geradas:
  - DistribuiÃ§Ã£o das classes originais.  
  - Matriz de confusÃ£o normalizada.  
  - Curva ROC e cÃ¡lculo da AUC.  

---

## ğŸ—‚ï¸ Dataset

O conjunto de dados utilizado neste projeto Ã© o **Pima Indians Diabetes Database**, disponibilizado publicamente no Kaggle.  

ğŸ“‚ **Fonte:**  
> [Diabetes Data Set â€“ Kaggle](https://www.kaggle.com/datasets/mathchi/diabetes-data-set/data)  
> *Base derivada do Pima Indians Diabetes Database (UCI Machine Learning Repository).*

### ğŸ“ˆ DescriÃ§Ã£o Geral
O dataset contÃ©m **768 observaÃ§Ãµes** de mulheres de origem Pima (populaÃ§Ã£o indÃ­gena norte-americana), com **8 variÃ¡veis preditoras** e **1 variÃ¡vel alvo binÃ¡ria** (`Outcome`), que indica se a paciente foi diagnosticada com diabetes tipo II.

### ğŸ” Estrutura das VariÃ¡veis

| VariÃ¡vel | DescriÃ§Ã£o | Tipo | Intervalo / Unidade |
|-----------|------------|------|---------------------|
| `Pregnancies` | NÃºmero de gestaÃ§Ãµes | NumÃ©rica (int) | 0 â€“ 17 |
| `Glucose` | ConcentraÃ§Ã£o de glicose plasmÃ¡tica (2h) | NumÃ©rica (int) | 0 â€“ 199 mg/dL |
| `BloodPressure` | PressÃ£o arterial diastÃ³lica | NumÃ©rica (int) | 0 â€“ 122 mmHg |
| `SkinThickness` | Espessura da dobra cutÃ¢nea do trÃ­ceps | NumÃ©rica (int) | 0 â€“ 99 mm |
| `Insulin` | NÃ­vel sÃ©rico de insulina em 2h | NumÃ©rica (int) | 0 â€“ 846 ÂµU/mL |
| `BMI` | Ãndice de massa corporal | NumÃ©rica (float) | 0 â€“ 67.1 kg/mÂ² |
| `DiabetesPedigreeFunction` | HistÃ³rico familiar de diabetes | NumÃ©rica (float) | 0.078 â€“ 2.42 |
| `Age` | Idade (anos) | NumÃ©rica (int) | 21 â€“ 81 |
| `Outcome` | DiagnÃ³stico (0 = NÃ£o DiabÃ©tico, 1 = DiabÃ©tico) | CategÃ³rica (binÃ¡ria) | â€” |

### ğŸ’¡ ObservaÃ§Ãµes Importantes
- VariÃ¡veis com valor â€œ0â€ foram tratadas como **valores ausentes** em atributos fisiologicamente impossÃ­veis.  
- O dataset apresenta **desbalanceamento moderado**, com aproximadamente **65% da classe 0** (nÃ£o diabÃ©ticos) e **35% da classe 1** (diabÃ©ticos).  
- Ã‰ amplamente utilizado como benchmark em tarefas de **classificaÃ§Ã£o mÃ©dica supervisionada**.  

> **Uso:** Os dados foram utilizados exclusivamente para fins **acadÃªmicos e de pesquisa**, respeitando as condiÃ§Ãµes de uso descritas no Kaggle.

---

## ğŸ“Š Resultados

| MÃ©trica | Classe 0 (NÃ£o Diabetes) | Classe 1 (Diabetes) | MÃ©dia Ponderada |
|----------|------------------------|----------------------|----------------|
| Precision | 0.84 | 0.61 | 0.76 |
| Recall | 0.74 | 0.74 | 0.74 |
| F1-Score | 0.79 | 0.67 | **0.74** |
| AcurÃ¡cia | â€” | â€” | **0.74** |

**Melhores parÃ¢metros:**  
`{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 10}`  

**F1-Score mÃ©dio (validaÃ§Ã£o cruzada):** 0.6868  

A combinaÃ§Ã£o **Random Forest + SMOTE** proporcionou um aumento significativo no *recall* da classe minoritÃ¡ria, aspecto crÃ­tico em diagnÃ³sticos clÃ­nicos sensÃ­veis.

---

## ğŸ§  DiscussÃ£o

O uso do **SMOTE** mitigou o impacto do desbalanceamento de classes, reduzindo falsos negativos sem causar sobreajuste perceptÃ­vel.  
O modelo apresentou **robustez estatÃ­stica** e **boa generalizaÃ§Ã£o**, validando o uso de pipelines integrados de balanceamento e modelagem nÃ£o linear em contextos biomÃ©dicos.

---

## ğŸ§© ExecuÃ§Ã£o

### ğŸ“¦ DependÃªncias
```bash
pip install pandas numpy matplotlib scikit-learn imbalanced-learn
```

### â–¶ï¸ ExecuÃ§Ã£o do Script
1. Edite o caminho do dataset no script:
   ```python
   file_path = '/caminho/para/seu/arquivo/diabetes.csv'
   ```
2. Execute:
   ```bash
   python randomforest+smote.py
   ```

Todos os resultados e grÃ¡ficos sÃ£o gerados automaticamente no terminal e em janelas interativas (*matplotlib*).

---

## ğŸ“ Estrutura do Projeto

```
ğŸ“¦ RandomForest_SMOTE/
 â”œâ”€â”€ randomforest+smote.py        # Script principal (executÃ¡vel)
 â”œâ”€â”€ README.md                    # Documento tÃ©cnico e metodolÃ³gico
 â””â”€â”€ data/
     â””â”€â”€ diabetes.csv             # Base de dados
```

---

## ğŸ§¾ ReferÃªncias BibliogrÃ¡ficas

- **Breiman, L.** (2001). *Random Forests*. *Machine Learning*, 45(1), 5â€“32.  
  https://doi.org/10.1023/A:1010933404324  
- **Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P.** (2002). *SMOTE: Synthetic Minority Over-sampling Technique*. *Journal of Artificial Intelligence Research*, 16, 321â€“357.  
  https://doi.org/10.1613/jair.953  
- **Pedregosa, F., et al.** (2011). *Scikit-learn: Machine Learning in Python*. *Journal of Machine Learning Research*, 12, 2825â€“2830.  
- **LemaÃ®tre, G., Nogueira, F., & Aridas, C. K.** (2017). *Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning*. *Journal of Machine Learning Research*, 18(17), 1â€“5.  

---

ğŸ“„ *Documento tÃ©cnico-acadÃªmico revisado, padronizado e alinhado ao formato BreaKHis, com Ãªnfase em clareza metodolÃ³gica, reprodutibilidade e integridade cientÃ­fica.*
